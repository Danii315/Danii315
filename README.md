# ğŸ‘‹ Daniel Cosmin Nedelcu 
ğŸ“Š Data Scientist | Machine Learning & IA  
ğŸ“ Madrid, EspaÃ±a  

<img src="https://img.shields.io/badge/PYTHON-3776AB?style=for-the-badge&logo=python&logoColor=white" height="26" /> <img src="https://img.shields.io/badge/SQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white" height="26" /> <img src="https://img.shields.io/badge/PANDAS-150458?style=for-the-badge&logo=pandas&logoColor=white" height="26" /> <img src="https://img.shields.io/badge/NUMPY-013243?style=for-the-badge&logo=numpy&logoColor=white" height="26" /> 

<img src="https://img.shields.io/badge/SCIKIT--LEARN-F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white" height="26" /> <img src="https://img.shields.io/badge/MACHINE%20LEARNING-0B1F2A?style=for-the-badge&logoColor=white" height="26" /> <img src="https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazonaws&logoColor=FF9900" height="26" />


Transformo datos en **pipelines, modelos y APIs** listos para producto: automatizados, reproducibles y pensados para generar impacto real.

---

## ğŸ§  Resumen Profesional
Data Scientist en formaciÃ³n especializada, con una base sÃ³lida en anÃ¡lisis de datos, estadÃ­stica y machine learning, y experiencia prÃ¡ctica en proyectos de Inteligencia Artificial aplicada.

Trabajo el ciclo completo del dato, desde la obtenciÃ³n y limpieza hasta el anÃ¡lisis, modelado y comunicaciÃ³n de resultados, con un enfoque orientado a negocio, producto e impacto real.

---

## ğŸ“ FormaciÃ³n
**Bootcamp de Data Engineering, Data Science e Inteligencia Artificial**  
**HACK A BOSS** Â· 24 semanas Â· Full-time Â· Online  

- MetodologÃ­a prÃ¡ctica basada en proyectos reales  
- Enfoque en empleabilidad, arquitectura y despliegue  
- Trabajo continuo con AWS, pipelines y ML aplicado  

---

## ğŸ§© Perfil TÃ©cnico

### ğŸ’» ProgramaciÃ³n
- **Python** â†’ ETL, automatizaciÃ³n, APIs, scripts
- **SQL** â†’ consultas, joins, agregaciones, diseÃ±o y carga de tablas

### ğŸ“Š Datos, AnÃ¡lisis y VisualizaciÃ³n
- **Pandas Â· NumPy**
- EDA y calidad de datos (validaciÃ³n, limpieza, normalizaciÃ³n)
- VisualizaciÃ³n: **Matplotlib / Seaborn / Plotly** *(segÃºn proyecto)*

### ğŸ¤– Machine Learning
- **scikit-learn**
- Modelos supervisados (clasificaciÃ³n/regresiÃ³n)
- EvaluaciÃ³n: accuracy, precision, recall, F1, RMSE
- Feature engineering bÃ¡sico + preparaciÃ³n de datasets

### â˜ï¸ Cloud & MLOps (AWS)
- **S3** (data lake), **Lambda**, **EventBridge**
- **RDS/Aurora (PostgreSQL)** para capa analÃ­tica
- **IAM** (roles/policies), gestiÃ³n de permisos
- **CloudWatch** (logs, monitorizaciÃ³n)
- AutomatizaciÃ³n de cargas masivas + incrementales (daily)

### ğŸ›  Herramientas
- **Git & GitHub**
- **FastAPI** (exposiciÃ³n de modelos / endpoints)
- **Jupyter Notebooks**, VS Code
- Consumo de **APIs REST**

---

## ğŸ§ª Proyectos Destacados

### ğŸ“Œ Video Game Intelligence Pipeline + ML API (RAWG)
**Objetivo:** construir un sistema end-to-end que extrae datos de videojuegos desde la API de RAWG, los procesa y los expone para anÃ¡lisis + predicciÃ³n mediante una API.

**QuÃ© hice / responsabilidades:**
- ExtracciÃ³n desde API (RAWG) con paginaciÃ³n y control de lÃ­mites
- **Carga masiva (initial)** y **carga incremental diaria (daily)** automatizada
- Persistencia en **S3** + control de estado/lock para evitar solapes
- TransformaciÃ³n y carga a **PostgreSQL (RDS/Aurora)** con esquema consistente
- Entrenamiento de modelos para predecir â€œÃ©xitoâ€ (segÃºn mÃ©tricas definidas)
- **API con FastAPI**: endpoints tipo `/predict`, `/ask-text` *(segÃºn diseÃ±o final)*
- MonitorizaciÃ³n y depuraciÃ³n con **CloudWatch**

**Resultado:**
- Pipeline reproducible y automatizado (initial + daily)
- Datos centralizados en RDS para anÃ¡lisis y consumo
- Servicio listo para integrar predicciones en producto

ğŸ”— Repositorio: **https://github.com/mcayuela89/GameScope_Video_Game_Intelligence_Pipeline_ML_API**

---

ğŸ“Œ Cinematic Data Analysis Â· TMDb
Objetivo: analizar datos cinematogrÃ¡ficos reales para identificar patrones de popularidad, gÃ©neros, votaciones e ingresos a partir de informaciÃ³n obtenida de la API pÃºblica de The Movie Database (TMDb).

Responsabilidades:

Consumo de API REST y extracciÃ³n de datos de pelÃ­culas

Limpieza, transformaciÃ³n y estructuraciÃ³n de datos (ETL) con Python

GeneraciÃ³n de datasets en formato CSV para anÃ¡lisis reproducible

AnÃ¡lisis exploratorio de datos (EDA) y visualizaciÃ³n de insights clave

Resultado:

IdentificaciÃ³n de gÃ©neros y caracterÃ­sticas asociados a mayor popularidad y recaudaciÃ³n

AnÃ¡lisis de relaciones entre duraciÃ³n, presupuesto, votaciones y taquilla

Pipeline de anÃ¡lisis documentado y reutilizable en Jupyter Notebooks

ğŸ”— Repositorio: https://github.com/mcayuela89/Cinematic_Data_Analysis_TMDb

---

## ğŸ’¼ QuÃ© puedo aportar a un equipo
âœ”ï¸ Capacidad de construir soluciones **end-to-end** (datos â†’ modelo â†’ API)  
âœ”ï¸ Mentalidad de **automatizaciÃ³n**, reproducibilidad y buenas prÃ¡cticas  
âœ”ï¸ Buen manejo de **AWS** (S3/Lambda/EventBridge/RDS/IAM/CloudWatch)  
âœ”ï¸ ComunicaciÃ³n clara y documentaciÃ³n para equipos tÃ©cnicos/no tÃ©cnicos  
âœ”ï¸ Aprendizaje rÃ¡pido y enfoque prÃ¡ctico orientado a producto  

---

## ğŸ¯ Objetivo Profesional
Incorporarme como **Data Engineer / ML Engineer Junior** en equipos orientados a producto, datos o innovaciÃ³n, donde pueda aportar desde el primer dÃ­a con pipelines, automatizaciÃ³n y modelos aplicados.

---

## ğŸ¤ Contacto
ğŸ“§ Email: **nedelcucosmin3@gmail.com**  
ğŸ’¼ LinkedIn: **https://www.linkedin.com/in/cosmin-daniel-nedelcu/**  
ğŸ™ GitHub: **https://github.com/Danii315** 
ğŸŒ Portfolio: **[TU_WEB]**

---

<!-- Opcional: stats (sustituye TU_USUARIO) -->
<!--
## ğŸ“ˆ GitHub Stats
![Stats](https://github-readme-stats.vercel.app/api?username=TU_USUARIO&show_icons=true&hide_title=true)
![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=TU_USUARIO&layout=compact)
-->

â­ Gracias por visitar mi perfil.
    Estoy abierto a nuevas oportunidades, colaboraciÃ³n y proyectos interesantes.
